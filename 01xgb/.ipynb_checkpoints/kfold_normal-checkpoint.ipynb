{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "np.unique(data.target )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold is an option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 06:03:29,492 <ipython-input-35-656408a59eee>[32] INFO fold n°0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.08553\tvalid_data-mlogloss:1.08534\n",
      "Multiple eval metrics have been passed: 'valid_data-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mlogloss hasn't improved in 200 rounds.\n",
      "[500]\ttrain-mlogloss:0.042973\tvalid_data-mlogloss:0.030253\n",
      "[1000]\ttrain-mlogloss:0.028812\tvalid_data-mlogloss:0.022452\n",
      "[1500]\ttrain-mlogloss:0.025265\tvalid_data-mlogloss:0.021684\n",
      "[2000]\ttrain-mlogloss:0.023576\tvalid_data-mlogloss:0.020708\n",
      "[2500]\ttrain-mlogloss:0.022735\tvalid_data-mlogloss:0.020126\n",
      "[3000]\ttrain-mlogloss:0.022149\tvalid_data-mlogloss:0.019587\n",
      "[3500]\ttrain-mlogloss:0.021808\tvalid_data-mlogloss:0.019356\n",
      "Stopping. Best iteration:\n",
      "[3619]\ttrain-mlogloss:0.021757\tvalid_data-mlogloss:0.019316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 06:03:30,111 <ipython-input-35-656408a59eee>[65] INFO fold n0, best_iter:3619, score:1.0000 val shape:(21, 4)\n",
      "2019-04-17 06:03:30,115 <ipython-input-35-656408a59eee>[32] INFO fold n°1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.085\tvalid_data-mlogloss:1.08626\n",
      "Multiple eval metrics have been passed: 'valid_data-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mlogloss hasn't improved in 200 rounds.\n",
      "[500]\ttrain-mlogloss:0.026665\tvalid_data-mlogloss:0.163585\n",
      "Stopping. Best iteration:\n",
      "[517]\ttrain-mlogloss:0.025913\tvalid_data-mlogloss:0.163016\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 06:03:30,273 <ipython-input-35-656408a59eee>[65] INFO fold n1, best_iter:517, score:0.9524 val shape:(21, 4)\n",
      "2019-04-17 06:03:30,274 <ipython-input-35-656408a59eee>[32] INFO fold n°2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.08517\tvalid_data-mlogloss:1.08504\n",
      "Multiple eval metrics have been passed: 'valid_data-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mlogloss hasn't improved in 200 rounds.\n",
      "[500]\ttrain-mlogloss:0.039932\tvalid_data-mlogloss:0.068637\n",
      "[1000]\ttrain-mlogloss:0.026786\tvalid_data-mlogloss:0.06184\n",
      "[1500]\ttrain-mlogloss:0.023694\tvalid_data-mlogloss:0.05968\n",
      "[2000]\ttrain-mlogloss:0.022064\tvalid_data-mlogloss:0.058123\n",
      "[2500]\ttrain-mlogloss:0.021288\tvalid_data-mlogloss:0.057166\n",
      "[3000]\ttrain-mlogloss:0.020879\tvalid_data-mlogloss:0.056038\n",
      "Stopping. Best iteration:\n",
      "[3078]\ttrain-mlogloss:0.02084\tvalid_data-mlogloss:0.055746\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 06:03:30,862 <ipython-input-35-656408a59eee>[65] INFO fold n2, best_iter:3078, score:1.0000 val shape:(21, 4)\n",
      "2019-04-17 06:03:30,866 <ipython-input-35-656408a59eee>[32] INFO fold n°3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.08553\tvalid_data-mlogloss:1.08519\n",
      "Multiple eval metrics have been passed: 'valid_data-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mlogloss hasn't improved in 200 rounds.\n",
      "[500]\ttrain-mlogloss:0.041934\tvalid_data-mlogloss:0.04188\n",
      "Stopping. Best iteration:\n",
      "[740]\ttrain-mlogloss:0.032161\tvalid_data-mlogloss:0.036333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 06:03:31,078 <ipython-input-35-656408a59eee>[65] INFO fold n3, best_iter:740, score:1.0000 val shape:(21, 4)\n",
      "2019-04-17 06:03:31,079 <ipython-input-35-656408a59eee>[32] INFO fold n°4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.08548\tvalid_data-mlogloss:1.0853\n",
      "Multiple eval metrics have been passed: 'valid_data-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-mlogloss hasn't improved in 200 rounds.\n",
      "[500]\ttrain-mlogloss:0.043437\tvalid_data-mlogloss:0.024832\n",
      "[1000]\ttrain-mlogloss:0.029696\tvalid_data-mlogloss:0.013904\n",
      "[1500]\ttrain-mlogloss:0.02638\tvalid_data-mlogloss:0.011739\n",
      "[2000]\ttrain-mlogloss:0.024558\tvalid_data-mlogloss:0.010513\n",
      "[2500]\ttrain-mlogloss:0.023615\tvalid_data-mlogloss:0.01\n",
      "[3000]\ttrain-mlogloss:0.022976\tvalid_data-mlogloss:0.009582\n",
      "[3500]\ttrain-mlogloss:0.022571\tvalid_data-mlogloss:0.009378\n",
      "[4000]\ttrain-mlogloss:0.02228\tvalid_data-mlogloss:0.009254\n",
      "[4500]\ttrain-mlogloss:0.022054\tvalid_data-mlogloss:0.0091\n",
      "Stopping. Best iteration:\n",
      "[4647]\ttrain-mlogloss:0.021983\tvalid_data-mlogloss:0.009026\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 06:03:31,946 <ipython-input-35-656408a59eee>[65] INFO fold n4, best_iter:4647, score:1.0000 val shape:(21, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 3) 0.9904761904761905\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "import logging\n",
    "format_str = '%(asctime)s %(filename)s[%(lineno)d] %(levelname)s %(message)s'\n",
    "format = logging.Formatter(format_str)\n",
    "logging.basicConfig(level=logging.DEBUG, format=format_str)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "folds = StratifiedKFold(n_splits=3, shuffle=True, random_state = 5)\n",
    "\n",
    "\n",
    "\n",
    "def train(X_data,  y_data,  X_test, cv=False ):\n",
    "    \n",
    "    num_fold = 5\n",
    "    num_class = 3\n",
    "    folds = KFold(n_splits=num_fold, shuffle=True, random_state=15)\n",
    "    oof = np.zeros((len(y_data),num_class))\n",
    "    predictions = np.zeros((len(X_test),num_class))\n",
    "    #start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_data.values, y_data.values)):\n",
    "        logger.info(\"fold n°{}\".format(fold_))\n",
    "        \n",
    "\n",
    "        trn_data = xgb.DMatrix(X_data.iloc[trn_idx], y_data.iloc[trn_idx])\n",
    "        val_data = xgb.DMatrix(X_data.iloc[val_idx], y_data.iloc[val_idx])\n",
    "        watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "        #np.random.seed(666)\n",
    "        params = {'eta': 0.01, \n",
    "                  'max_depth': 11, \n",
    "                  'subsample': 0.8, \n",
    "                  'colsample_bytree': 0.8,                   \n",
    "                  'objective': 'multi:softprob',\n",
    "                  'num_class': num_class,\n",
    "                  'eval_metric': 'mlogloss', \n",
    "                  'silent': True, \n",
    "                  'nthread': 4}\n",
    "        \n",
    "        num_round = 30000\n",
    "\n",
    "        \n",
    "        clf = xgb.train(params,\n",
    "                          dtrain=trn_data, \n",
    "                          num_boost_round=num_round, \n",
    "                          evals=watchlist, \n",
    "                          early_stopping_rounds=200, \n",
    "                          verbose_eval=500, \n",
    "                           )\n",
    "        oof[val_idx] = clf.predict(xgb.DMatrix(X_data.iloc[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "        \n",
    "\n",
    "        #oof[val_idx] = clf.predict(X_data.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        score = accuracy_score(y_data.values[val_idx], oof.argmax(axis=1)[val_idx],)\n",
    "        logger.info(f'fold n{fold_}, best_iter:{clf.best_iteration}, score:{score:6.4f} val shape:{X_data.iloc[val_idx].shape}')\n",
    "\n",
    "\n",
    "        if cv:\n",
    "            predictions += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit)\n",
    "        else:\n",
    "            logger.info('Cv is disable, will train with full train data')\n",
    "            all_train = xgb.DMatrix(X_data, y_data)\n",
    "            clf = xgb.train(params,\n",
    "                           dtrain=all_train, \n",
    "                           num_boost_round=clf.best_ntree_limit, \n",
    "                          #evals=watchlist, \n",
    "                          #early_stopping_rounds=200, \n",
    "                          verbose_eval=500, \n",
    "                           )\n",
    "            predictions += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit)\n",
    "            break\n",
    "        \n",
    "    predictions = predictions/(fold_ + 1)\n",
    "    if cv:\n",
    "        score = accuracy_score(y_data.values, oof.argmax(axis=1),)\n",
    "    return predictions, score\n",
    "\n",
    "train_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "train_target = pd.DataFrame(iris.target, columns=['label'])\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_data,train_target,test_size=0.3)\n",
    "\n",
    "predictions, score = train(X_train,y_train,X_test,cv=True)\n",
    "\n",
    "print(predictions.shape, score)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.train?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
