{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'target', 'target_names']\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "data = load_iris()\n",
    "np.unique(data.target )\n",
    "\n",
    "print(dir(data))\n",
    "print(data.feature_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "data = load_wine()\n",
    "np.unique(data.target )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 02:18:45,797 <ipython-input-5-38efeb09053d>[31] INFO fold n°0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 02:18:46,141 <ipython-input-5-38efeb09053d>[57] INFO fold n0, best_iter:44, val shape:(21, 4)\n",
      "2019-04-17 02:18:46,150 <ipython-input-5-38efeb09053d>[31] INFO fold n°1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's multi_logloss: 0.0575746\tvalid_1's multi_logloss: 0.110612\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 02:18:46,544 <ipython-input-5-38efeb09053d>[57] INFO fold n1, best_iter:94, val shape:(21, 4)\n",
      "2019-04-17 02:18:46,550 <ipython-input-5-38efeb09053d>[31] INFO fold n°2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's multi_logloss: 0.0444158\tvalid_1's multi_logloss: 0.0912174\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2000]\ttraining's multi_logloss: 0.014799\tvalid_1's multi_logloss: 0.0057197\n",
      "Early stopping, best iteration is:\n",
      "[2401]\ttraining's multi_logloss: 0.0147935\tvalid_1's multi_logloss: 0.00571965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 02:18:49,548 <ipython-input-5-38efeb09053d>[57] INFO fold n2, best_iter:2401, val shape:(21, 4)\n",
      "2019-04-17 02:18:49,593 <ipython-input-5-38efeb09053d>[31] INFO fold n°3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 02:18:49,937 <ipython-input-5-38efeb09053d>[57] INFO fold n3, best_iter:32, val shape:(21, 4)\n",
      "2019-04-17 02:18:49,954 <ipython-input-5-38efeb09053d>[31] INFO fold n°4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's multi_logloss: 0.0807604\tvalid_1's multi_logloss: 0.354552\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 02:18:50,316 <ipython-input-5-38efeb09053d>[57] INFO fold n4, best_iter:63, val shape:(21, 4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's multi_logloss: 0.056934\tvalid_1's multi_logloss: 0.0380282\n",
      "(45, 3) 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "import logging\n",
    "format_str = '%(asctime)s %(filename)s[%(lineno)d] %(levelname)s %(message)s'\n",
    "format = logging.Formatter(format_str)\n",
    "logging.basicConfig(level=logging.DEBUG, format=format_str)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "folds = StratifiedKFold(n_splits=3, shuffle=True, random_state = 5)\n",
    "\n",
    "\n",
    "\n",
    "def train(X_data,  y_data,  X_test ):\n",
    "    \n",
    "    num_fold = 5\n",
    "    num_class = 3\n",
    "    folds = KFold(n_splits=num_fold, shuffle=True, random_state=15)\n",
    "    oof = np.zeros((len(y_data),num_class))\n",
    "    predictions = np.zeros((len(X_test),num_class))\n",
    "    #start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_data.values, y_data.values)):\n",
    "        logger.info(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(X_data.iloc[trn_idx], y_data.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(X_data.iloc[val_idx], y_data.iloc[val_idx], reference=trn_data)\n",
    "\n",
    "        #np.random.seed(666)\n",
    "        params={\n",
    "            #'verbose':2,\n",
    "            'learning_rate':0.1,\n",
    "            'lambda_l1':0.1,\n",
    "            'lambda_l2':0.2,\n",
    "            'max_depth':4,\n",
    "            'objective':'multiclass',\n",
    "            'num_class':num_class,  #lightgbm.basic.LightGBMError: b'Number of classes should be specified and greater than 1 for multiclass training'  \n",
    "            #'device':'gpu',\n",
    "            #'gpu_platform_id': 1, 'gpu_device_id': 0\n",
    "        }\n",
    "        num_round = 30000\n",
    "        clf = lgb.train(params,\n",
    "                        trn_data,\n",
    "                        num_round,\n",
    "                        valid_sets=[trn_data, val_data],\n",
    "                        verbose_eval=2000,\n",
    "                        early_stopping_rounds=200)\n",
    "        \n",
    "\n",
    "        oof[val_idx] = clf.predict(X_data.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        logger.info(f'fold n{fold_}, best_iter:{clf.best_iteration}, val shape:{X_data.iloc[val_idx].shape}')\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] =  X_data.columns\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "        predictions += clf.predict(X_test, num_iteration=clf.best_iteration)\n",
    "    predictions = predictions/folds.n_splits\n",
    "    oof = oof.argmax(axis=1)\n",
    "    score = accuracy_score(oof,y_data.values)\n",
    "    return predictions, score\n",
    "\n",
    "train_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "train_target = pd.DataFrame(iris.target, columns=['label'])\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_data,train_target,test_size=0.3)\n",
    "\n",
    "predictions, score = train(X_train,y_train,X_test)\n",
    "\n",
    "print(predictions.shape, score)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KFold is an option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 02:33:08,368 <ipython-input-26-0e8683dfc7e4>[31] INFO fold n°0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 02:33:08,716 <ipython-input-26-0e8683dfc7e4>[59] INFO fold n0, best_iter:62, score:0.9524 val shape:(21, 4)\n",
      "2019-04-17 02:33:08,719 <ipython-input-26-0e8683dfc7e4>[69] INFO Cv is disable, will train with full train data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's multi_logloss: 0.0557193\tvalid_1's multi_logloss: 0.152055\n",
      "(45, 3) 0.9523809523809523\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "import logging\n",
    "format_str = '%(asctime)s %(filename)s[%(lineno)d] %(levelname)s %(message)s'\n",
    "format = logging.Formatter(format_str)\n",
    "logging.basicConfig(level=logging.DEBUG, format=format_str)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "folds = StratifiedKFold(n_splits=3, shuffle=True, random_state = 5)\n",
    "\n",
    "\n",
    "\n",
    "def train(X_data,  y_data,  X_test, cv=False ):\n",
    "    \n",
    "    num_fold = 5\n",
    "    num_class = 3\n",
    "    folds = KFold(n_splits=num_fold, shuffle=True, random_state=15)\n",
    "    oof = np.zeros((len(y_data),num_class))\n",
    "    predictions = np.zeros((len(X_test),num_class))\n",
    "    #start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_data.values, y_data.values)):\n",
    "        logger.info(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(X_data.iloc[trn_idx], y_data.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(X_data.iloc[val_idx], y_data.iloc[val_idx], reference=trn_data)\n",
    "\n",
    "        #np.random.seed(666)\n",
    "        params={\n",
    "            #'verbose':2,\n",
    "            'learning_rate':0.1,\n",
    "            'lambda_l1':0.1,\n",
    "            'lambda_l2':0.2,\n",
    "            'max_depth':4,\n",
    "            'objective':'multiclass',\n",
    "            'num_class':num_class,  #lightgbm.basic.LightGBMError: b'Number of classes should be specified and greater than 1 for multiclass training'  \n",
    "            #'device':'gpu',\n",
    "            #'gpu_platform_id': 1, 'gpu_device_id': 0\n",
    "        }\n",
    "        num_round = 30000\n",
    "        clf = lgb.train(params,\n",
    "                        trn_data,\n",
    "                        num_round,\n",
    "                        valid_sets=[trn_data, val_data],\n",
    "                        verbose_eval=2000,\n",
    "                        early_stopping_rounds=200)\n",
    "        \n",
    "\n",
    "        oof[val_idx] = clf.predict(X_data.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        score = accuracy_score(y_data.values[val_idx], oof.argmax(axis=1)[val_idx],)\n",
    "        logger.info(f'fold n{fold_}, best_iter:{clf.best_iteration}, score:{score:6.4f} val shape:{X_data.iloc[val_idx].shape}')\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] =  X_data.columns\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        if cv:\n",
    "            predictions += clf.predict(X_test, num_iteration=clf.best_iteration)\n",
    "        else:\n",
    "            logger.info('Cv is disable, will train with full train data')\n",
    "            all_train = lgb.Dataset(X_data, y_data)\n",
    "            clf = lgb.train(params,\n",
    "                all_train,\n",
    "                #num_round,\n",
    "                num_boost_round=clf.best_iteration,\n",
    "                valid_sets=[all_train],\n",
    "                verbose_eval=2000,\n",
    "                )\n",
    "            predictions += clf.predict(X_test, num_iteration=clf.best_iteration)\n",
    "            break\n",
    "        \n",
    "    predictions = predictions/(fold_ + 1)\n",
    "    if cv:\n",
    "        score = accuracy_score(y_data.values, oof.argmax(axis=1),)\n",
    "    return predictions, score\n",
    "\n",
    "train_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "train_target = pd.DataFrame(iris.target, columns=['label'])\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_data,train_target,test_size=0.3)\n",
    "\n",
    "predictions, score = train(X_train,y_train,X_test,cv=False)\n",
    "\n",
    "print(predictions.shape, score)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.21976062e-03, 2.60045835e-03, 9.94179781e-01],\n",
       "       [9.97063939e-01, 2.10587025e-03, 8.30191040e-04],\n",
       "       [3.20236048e-03, 7.99057548e-03, 9.88807064e-01],\n",
       "       [5.12637579e-03, 1.94761178e-01, 8.00112446e-01],\n",
       "       [1.12414238e-03, 8.00723498e-03, 9.90868623e-01],\n",
       "       [5.78657694e-03, 9.74239953e-01, 1.99734698e-02],\n",
       "       [8.91810047e-03, 6.28298381e-01, 3.62783519e-01],\n",
       "       [3.31297382e-03, 9.83142453e-01, 1.35445733e-02],\n",
       "       [3.20236048e-03, 7.99057548e-03, 9.88807064e-01],\n",
       "       [5.85551783e-02, 9.22782251e-01, 1.86625707e-02],\n",
       "       [9.92663557e-01, 6.46664121e-03, 8.69801599e-04],\n",
       "       [9.92706516e-01, 6.46692106e-03, 8.26562895e-04],\n",
       "       [2.82062578e-03, 1.07161165e-01, 8.90018209e-01],\n",
       "       [9.97063939e-01, 2.10587025e-03, 8.30191040e-04],\n",
       "       [9.96522731e-01, 2.49404791e-03, 9.83221174e-04],\n",
       "       [4.70619337e-03, 9.80835112e-01, 1.44586944e-02],\n",
       "       [7.70795620e-03, 9.66559297e-01, 2.57327469e-02],\n",
       "       [9.91625419e-01, 6.62168515e-03, 1.75289566e-03],\n",
       "       [1.12869683e-03, 3.98818754e-03, 9.94883116e-01],\n",
       "       [2.75198948e-03, 9.89182522e-01, 8.06548838e-03],\n",
       "       [1.12414238e-03, 8.00723498e-03, 9.90868623e-01],\n",
       "       [1.92560218e-03, 9.91572671e-01, 6.50172649e-03],\n",
       "       [9.95851829e-01, 3.31898901e-03, 8.29181795e-04],\n",
       "       [1.13122979e-03, 1.75299512e-03, 9.97115775e-01],\n",
       "       [9.95851829e-01, 3.31898901e-03, 8.29181795e-04],\n",
       "       [7.23735509e-03, 4.67341079e-01, 5.25421566e-01],\n",
       "       [9.96109588e-01, 2.90759813e-03, 9.82813546e-04],\n",
       "       [4.17569848e-03, 9.87747986e-01, 8.07631525e-03],\n",
       "       [1.12414238e-03, 8.00723498e-03, 9.90868623e-01],\n",
       "       [8.50126896e-03, 9.64395782e-01, 2.71029492e-02],\n",
       "       [9.17814119e-01, 7.55061016e-02, 6.67977956e-03],\n",
       "       [1.12414238e-03, 8.00723498e-03, 9.90868623e-01],\n",
       "       [8.91810047e-03, 6.28298381e-01, 3.62783519e-01],\n",
       "       [7.59638648e-03, 9.52568720e-01, 3.98348932e-02],\n",
       "       [9.95851829e-01, 3.31898901e-03, 8.29181795e-04],\n",
       "       [5.12637579e-03, 1.94761178e-01, 8.00112446e-01],\n",
       "       [3.21530771e-03, 3.97985634e-03, 9.92804836e-01],\n",
       "       [1.98166863e-03, 9.88871942e-01, 9.14638924e-03],\n",
       "       [9.95851829e-01, 3.31898901e-03, 8.29181795e-04],\n",
       "       [9.96522731e-01, 2.49404791e-03, 9.83221174e-04],\n",
       "       [1.46001484e-02, 9.36657758e-01, 4.87420937e-02],\n",
       "       [4.26187219e-03, 1.22470621e-02, 9.83491066e-01],\n",
       "       [9.97063939e-01, 2.10587025e-03, 8.30191040e-04],\n",
       "       [1.12800417e-03, 4.59942045e-03, 9.94272575e-01],\n",
       "       [9.96522731e-01, 2.49404791e-03, 9.83221174e-04]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_0's multi_logloss: 0.254046\n",
      "[100]\tvalid_0's multi_logloss: 0.330064\n",
      "[1, 1, 2, 2, 1, 0, 2, 2, 0, 2, 0, 1, 1, 2, 1, 0, 2, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 0, 0, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2, 2]\n",
      "0.9111111111111111\n",
      "CPU times: user 46 s, sys: 11.9 ms, total: 46 s\n",
      "Wall time: 651 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris=datasets.load_iris()\n",
    "X_train,X_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=0.3)\n",
    "import numpy as np\n",
    "train_data=lgb.Dataset(X_train,label=y_train)\n",
    "validation_data=lgb.Dataset(X_test,label=y_test)\n",
    "params={\n",
    "    #'verbose':2,\n",
    "    'learning_rate':0.1,\n",
    "    'lambda_l1':0.1,\n",
    "    'lambda_l2':0.2,\n",
    "    'max_depth':4,\n",
    "    'objective':'multiclass',\n",
    "    'num_class':3,  #lightgbm.basic.LightGBMError: b'Number of classes should be specified and greater than 1 for multiclass training'  \n",
    "    #'device':'gpu',\n",
    "    'gpu_platform_id': 1, 'gpu_device_id': 0\n",
    "}\n",
    "clf=lgb.train(params,train_data,valid_sets=[validation_data], verbose_eval=50,)\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "y_pred=clf.predict(X_test)\n",
    "y_pred=[list(x).index(max(x)) for x in y_pred]\n",
    "print(y_pred)\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
