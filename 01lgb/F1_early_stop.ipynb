{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-04-17 23:33:08,893 <ipython-input-1-ce4a77eab952>[46] INFO fold n°0\n",
      "/apps/dslab/anaconda/python3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "2019-04-17 23:33:09,098 <ipython-input-1-ce4a77eab952>[77] INFO fold n0, best_iter:16, score:0.8571 val shape:(21, 4)\n",
      "2019-04-17 23:33:09,108 <ipython-input-1-ce4a77eab952>[87] INFO CV is disable, will train with full train data with iter:16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "[10]\ttraining's f1: 0.9881\tvalid_1's f1: 0.8544\n",
      "[20]\ttraining's f1: 1\tvalid_1's f1: 0.8584\n",
      "[30]\ttraining's f1: 1\tvalid_1's f1: 0.8584\n",
      "[40]\ttraining's f1: 1\tvalid_1's f1: 0.8584\n",
      "[50]\ttraining's f1: 1\tvalid_1's f1: 0.8584\n",
      "[60]\ttraining's f1: 1\tvalid_1's f1: 0.8584\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's f1: 1\tvalid_1's f1: 0.8584\n",
      "[10]\ttraining's f1: 0.962\n",
      "(45, 3) 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score,accuracy_score\n",
    "import logging\n",
    "format_str = '%(asctime)s %(filename)s[%(lineno)d] %(levelname)s %(message)s'\n",
    "format = logging.Formatter(format_str)\n",
    "logging.basicConfig(level=logging.DEBUG, format=format_str)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "folds = StratifiedKFold(n_splits=3, shuffle=True, random_state = 5)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    num_sample = len(y_true)\n",
    "    y_hat =  y_hat.reshape(-1, num_sample).T.argmax(axis=1) \n",
    "    #y_hat = np.round(y_hat) # scikits f1 doesn't like probabilities\n",
    "    score = f1_score(y_true, y_hat, average='weighted')\n",
    "    return 'f1', round(score, 4) , True\n",
    "\n",
    "# evals_result = {}\n",
    "\n",
    "# clf = lgb.train(param, train_data, valid_sets=[val_data, train_data], valid_names=['val', 'train'], feval=lgb_f1_score, evals_result=evals_result)\n",
    "\n",
    "# lgb.plot_metric(evals_result, metric='f1')\n",
    "\n",
    "\n",
    "def train(X_data,  y_data,  X_test, cv=False ):\n",
    "    \n",
    "    num_fold = 5\n",
    "    num_class = 3\n",
    "    folds = KFold(n_splits=num_fold, shuffle=True, random_state=15)\n",
    "    oof = np.zeros((len(y_data),num_class))\n",
    "    predictions = np.zeros((len(X_test),num_class))\n",
    "    #start = time.time()\n",
    "    feature_importance_df = pd.DataFrame()\n",
    "\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_data.values, y_data.values)):\n",
    "        logger.info(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(X_data.iloc[trn_idx], y_data.iloc[trn_idx])\n",
    "        val_data = lgb.Dataset(X_data.iloc[val_idx], y_data.iloc[val_idx], reference=trn_data)\n",
    "\n",
    "        #np.random.seed(666)\n",
    "        params={\n",
    "            #'verbose':2,\n",
    "            'learning_rate':0.1,\n",
    "            'lambda_l1':0.1,\n",
    "            'lambda_l2':0.2,\n",
    "            'max_depth':4,\n",
    "            'objective':'multiclass',\n",
    "            'metric': 'None', # which is need when early stop by feval, such as F1\n",
    "            'num_class':num_class,  #lightgbm.basic.LightGBMError: b'Number of classes should be specified and greater than 1 for multiclass training'  \n",
    "            #'device':'gpu',\n",
    "            #'gpu_platform_id': 1, 'gpu_device_id': 0\n",
    "        }\n",
    "        num_round = 30000\n",
    "        clf = lgb.train(params,\n",
    "                        trn_data,\n",
    "                        num_round,\n",
    "                        valid_sets=[trn_data, val_data], \n",
    "                        feval=lgb_f1_score,\n",
    "                        verbose_eval=10,\n",
    "                        \n",
    "                        early_stopping_rounds=50)\n",
    "        \n",
    "\n",
    "        oof[val_idx] = clf.predict(X_data.iloc[val_idx], num_iteration=clf.best_iteration)\n",
    "        \n",
    "        score = accuracy_score(y_data.values[val_idx], oof.argmax(axis=1)[val_idx],)\n",
    "        logger.info(f'fold n{fold_}, best_iter:{clf.best_iteration}, score:{score:6.4f} val shape:{X_data.iloc[val_idx].shape}')\n",
    "\n",
    "        fold_importance_df = pd.DataFrame()\n",
    "        fold_importance_df[\"feature\"] =  X_data.columns\n",
    "        fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "        fold_importance_df[\"fold\"] = fold_ + 1\n",
    "        feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "        if cv:\n",
    "            predictions += clf.predict(X_test, num_iteration=clf.best_iteration)\n",
    "        else:\n",
    "            logger.info(f'CV is disable, will train with full train data with iter:{clf.best_iteration}')\n",
    "            all_train = lgb.Dataset(X_data, y_data)\n",
    "            evals_result = {}\n",
    "            clf = lgb.train(params,\n",
    "                all_train,\n",
    "                num_boost_round =clf.best_iteration,\n",
    "                #num_boost_round=\n",
    "                valid_sets=[all_train],\n",
    "                feval=lgb_f1_score,\n",
    "                verbose_eval=10,\n",
    "                evals_result=evals_result\n",
    "                )\n",
    "            predictions += clf.predict(X_test, num_iteration=clf.best_iteration)\n",
    "            #print('evals_result', evals_result)\n",
    "            break\n",
    "        \n",
    "    predictions = predictions/(fold_ + 1)\n",
    "    if cv:\n",
    "        score = accuracy_score(y_data.values, oof.argmax(axis=1),)\n",
    "    return predictions, score\n",
    "\n",
    "train_data = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "train_target = pd.DataFrame(iris.target, columns=['label'])\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(train_data,train_target,test_size=0.3,random_state=0 )\n",
    "\n",
    "predictions, score = train(X_train,y_train,X_test,cv=False)\n",
    "\n",
    "print(predictions.shape, score)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
